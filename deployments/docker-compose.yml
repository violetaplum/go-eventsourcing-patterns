services:
  postgres:
    image: postgres:latest
    environment:
      POSTGRES_DB: eventstore
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
    ports:
      - "5432:5432"
    volumes:
      - ./postgres/init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user -d eventstore"]
      interval: 5s
      timeout: 5s
      retries: 5



  kafka:
    image: confluentinc/cp-kafka:latest
    environment:
      KAFKA_PROCESS_ROLES: 'broker,controller' # KRaft 모드 활성화, zookeeper 없이 실행 가능하게함
      KAFKA_NODE_ID: 1 # 노드 ID
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:29093' # 컨트롤러 쿼텀 설정

      # 리스너 관련 설정 -> broker
      KAFKA_LISTENERS: 'PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:29093'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka:9092'

      # 클러스터 식별자
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'


      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1

      # KRaft 모드 초기화를 위한 중요 설정
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'


      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qg'# 클러스터 식별을 위한 UUID

      TRIES: 0
      MAX_TRIES: 10
    ports:
      - "9092:9092"
    volumes:
      - kafka_data:/tmp/kraft-combined-logs
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:9092 --list"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      restart_policy:
        condition: on-failure
        max_attempts: 3
    command: >
      bash -c '
      echo "Kafka KRaft 모드 초기화..."
      
      # 클러스터 ID 형식 설정
      export CLUSTER_ID=$(kafka-storage random-uuid)
      echo "생성된 클러스터 ID: $CLUSTER_ID"
      
      # 저장소 디렉토리 포맷팅
      echo "저장소 디렉토리 포맷팅 중..."
      kafka-storage format -t $CLUSTER_ID -c /etc/kafka/kraft/server.properties
      
      # Kafka 서버 시작
      echo "Kafka 서버 시작 중..."
      /etc/confluent/docker/run &
      
      # Kafka가 시작될 때까지 대기
      echo "Kafka 서버가 시작될 때까지 대기 중..."
      sleep 30
      
      # 토픽 생성 시도 (최대 10회)
      MAX_TRIES=10
      TRIES=0
      SUCCESS=false
      
      while [ $TRIES -lt $MAX_TRIES ] && [ "$SUCCESS" = "false" ]; do
      if kafka-topics --bootstrap-server localhost:9092 --list; then
      echo "Kafka 서버에 연결 성공!"
      
      # 토픽 생성
      echo "토픽 생성 중..."
      kafka-topics --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic account-events --if-not-exists
      kafka-topics --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic audit-logs --if-not-exists
      
      SUCCESS=true
      else
      TRIES=$((TRIES+1))
      echo "Kafka 서버 연결 대기 중... (시도 $TRIES/$MAX_TRIES)"
      sleep 10
      fi
      done
      
      if [ "$SUCCESS" = "false" ]; then
      echo "Kafka 서버 연결 실패 - 타임아웃"
      fi
      
      # 메인 프로세스 유지
      wait
      '


  account-api:
    build:
      context: ..
      dockerfile: deployments/app/Dockerfile
      target: account-app
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_started
      otel-collector:
        condition: service_started
    environment:
      DB_HOST: postgres
      DB_NAME: user
      DB_PASSWORD: password
      KAFKA_BROKERS: kafka:9092
      KAFKA_TOPIC: account-events
      OTEL_EXPORTER_OTLP_ENDPOINT: "otel-collector:4317"
      OTEL_SERVICE_NAME: "account-api"
    ports:
      - "8080:8080"

  event-processor:
    build:
      context: ..
      dockerfile: deployments/app/Dockerfile
      target: event-app # 멀티스테이지 Dockerfile 에서 특정 스테이지를 지정하기 위해 사용됨
      # 지금같은 경우는 Dockerfile 에 builder, account-app, event-processor 세가지로 나뉘어있음
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_healthy
      account-api:
        condition: service_started
      otel-collector:
        condition: service_started
    environment:
      DB_HOST: postgres
      DB_NAME: eventstore
      DB_USER: user
      DB_PASSWORD: password
      KAFKA_BROKERS: kafka:9092
      KAFKA_TOPIC: account-events    # account-events 토픽으로 설정되어 있는지 확인
      KAFKA_GROUP_ID: event-processor-group
      OTEL_EXPORTER_OTLP_ENDPOINT: "otel-collector:4317"
      OTEL_SERVICE_NAME: "event-processor"



  otel-collector:
    image: otel/opentelemetry-collector-contrib:latest
    command: ["--config=/etc/otel-collector-config.yaml"]
    volumes:
      - ./otel-collector-config.yaml:/etc/otel-collector-config.yaml
    ports:
      - "4317:4317" # OTLP gRPC
      - "4318:4318" # OTLP HTTP
      - "8888:8888" # metrics
      - "8889:8889" # prometheus metrics
    depends_on:
      jaeger:
        condition: service_started


  jaeger:
    image: jaegertracing/all-in-one:latest
    environment:
      - COLLECTOR_OTLP_GRPC_HOST_PORT=:14317  # 올바른 환경 변수 (콜론 포함)
      - COLLECTOR_OTLP_HTTP_HOST_PORT=:14318  # HTTP 포트도 변경
    ports:
      - "16686:16686" # UI
      - "14250:14250" # jaeger-collector
      - "14317:14317" # OTLP gRPC 포트
      - "14318:14318" # OTLP HTTP 포트


volumes:
  kafka_data: